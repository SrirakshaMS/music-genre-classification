{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "203/203 [==============================] - 7s 12ms/step - loss: 1.9005 - accuracy: 0.2994 - val_loss: 1.3762 - val_accuracy: 0.4972\n",
      "Epoch 2/50\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 1.4114 - accuracy: 0.4890 - val_loss: 1.1279 - val_accuracy: 0.5889\n",
      "Epoch 3/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 1.2353 - accuracy: 0.5532 - val_loss: 1.0341 - val_accuracy: 0.6167\n",
      "Epoch 4/50\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 1.1138 - accuracy: 0.6072 - val_loss: 0.8897 - val_accuracy: 0.6736\n",
      "Epoch 5/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 1.0116 - accuracy: 0.6412 - val_loss: 0.8215 - val_accuracy: 0.7167\n",
      "Epoch 6/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.9519 - accuracy: 0.6721 - val_loss: 0.7763 - val_accuracy: 0.7486\n",
      "Epoch 7/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.8736 - accuracy: 0.6899 - val_loss: 0.7450 - val_accuracy: 0.7444\n",
      "Epoch 8/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.8134 - accuracy: 0.7174 - val_loss: 0.6590 - val_accuracy: 0.7764\n",
      "Epoch 9/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.7580 - accuracy: 0.7379 - val_loss: 0.6295 - val_accuracy: 0.7917\n",
      "Epoch 10/50\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 0.7074 - accuracy: 0.7520 - val_loss: 0.6025 - val_accuracy: 0.8042\n",
      "Epoch 11/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.6706 - accuracy: 0.7698 - val_loss: 0.5743 - val_accuracy: 0.8139\n",
      "Epoch 12/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.6490 - accuracy: 0.7812 - val_loss: 0.5467 - val_accuracy: 0.8208\n",
      "Epoch 13/50\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 0.5957 - accuracy: 0.7928 - val_loss: 0.5628 - val_accuracy: 0.8319\n",
      "Epoch 14/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.5713 - accuracy: 0.8073 - val_loss: 0.5312 - val_accuracy: 0.8347\n",
      "Epoch 15/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.5432 - accuracy: 0.8194 - val_loss: 0.5055 - val_accuracy: 0.8389\n",
      "Epoch 16/50\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 0.5153 - accuracy: 0.8265 - val_loss: 0.5070 - val_accuracy: 0.8361\n",
      "Epoch 17/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.4948 - accuracy: 0.8354 - val_loss: 0.5126 - val_accuracy: 0.8458\n",
      "Epoch 18/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.4818 - accuracy: 0.8382 - val_loss: 0.5076 - val_accuracy: 0.8472\n",
      "Epoch 19/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.4489 - accuracy: 0.8460 - val_loss: 0.4837 - val_accuracy: 0.8514\n",
      "Epoch 20/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.4371 - accuracy: 0.8512 - val_loss: 0.4658 - val_accuracy: 0.8597\n",
      "Epoch 21/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.4292 - accuracy: 0.8549 - val_loss: 0.4885 - val_accuracy: 0.8611\n",
      "Epoch 22/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.3928 - accuracy: 0.8694 - val_loss: 0.4940 - val_accuracy: 0.8597\n",
      "Epoch 23/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.3894 - accuracy: 0.8704 - val_loss: 0.4541 - val_accuracy: 0.8736\n",
      "Epoch 24/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.3662 - accuracy: 0.8764 - val_loss: 0.4761 - val_accuracy: 0.8792\n",
      "Epoch 25/50\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 0.3626 - accuracy: 0.8827 - val_loss: 0.4601 - val_accuracy: 0.8722\n",
      "Epoch 26/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.3404 - accuracy: 0.8830 - val_loss: 0.4730 - val_accuracy: 0.8764\n",
      "Epoch 27/50\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 0.3208 - accuracy: 0.8934 - val_loss: 0.4835 - val_accuracy: 0.8750\n",
      "Epoch 28/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.3331 - accuracy: 0.8894 - val_loss: 0.4336 - val_accuracy: 0.8917\n",
      "Epoch 29/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.3156 - accuracy: 0.8982 - val_loss: 0.4345 - val_accuracy: 0.8806\n",
      "Epoch 30/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.3095 - accuracy: 0.8983 - val_loss: 0.4277 - val_accuracy: 0.8819\n",
      "Epoch 31/50\n",
      "203/203 [==============================] - 2s 8ms/step - loss: 0.2898 - accuracy: 0.9050 - val_loss: 0.4679 - val_accuracy: 0.8806\n",
      "Epoch 32/50\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 0.2783 - accuracy: 0.9051 - val_loss: 0.4559 - val_accuracy: 0.8750\n",
      "Epoch 33/50\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 0.2743 - accuracy: 0.9141 - val_loss: 0.4680 - val_accuracy: 0.8847\n",
      "Epoch 34/50\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 0.2579 - accuracy: 0.9149 - val_loss: 0.4690 - val_accuracy: 0.8875\n",
      "Epoch 35/50\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 0.2626 - accuracy: 0.9118 - val_loss: 0.4874 - val_accuracy: 0.8792\n",
      "Epoch 36/50\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 0.2504 - accuracy: 0.9223 - val_loss: 0.4747 - val_accuracy: 0.8847\n",
      "Epoch 37/50\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 0.2474 - accuracy: 0.9214 - val_loss: 0.4542 - val_accuracy: 0.8889\n",
      "Epoch 38/50\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 0.2485 - accuracy: 0.9170 - val_loss: 0.4672 - val_accuracy: 0.8847\n",
      "Epoch 39/50\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 0.2250 - accuracy: 0.9272 - val_loss: 0.4794 - val_accuracy: 0.8833\n",
      "Epoch 40/50\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 0.2331 - accuracy: 0.9246 - val_loss: 0.5034 - val_accuracy: 0.8722\n",
      "Epoch 41/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.2137 - accuracy: 0.9306 - val_loss: 0.5197 - val_accuracy: 0.8764\n",
      "Epoch 42/50\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 0.2000 - accuracy: 0.9348 - val_loss: 0.4899 - val_accuracy: 0.8889\n",
      "Epoch 43/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.2291 - accuracy: 0.9285 - val_loss: 0.4971 - val_accuracy: 0.8875\n",
      "Epoch 44/50\n",
      "203/203 [==============================] - 2s 8ms/step - loss: 0.2000 - accuracy: 0.9376 - val_loss: 0.5133 - val_accuracy: 0.8806\n",
      "Epoch 45/50\n",
      "203/203 [==============================] - 2s 9ms/step - loss: 0.2040 - accuracy: 0.9351 - val_loss: 0.4970 - val_accuracy: 0.8931\n",
      "Epoch 46/50\n",
      "203/203 [==============================] - 2s 11ms/step - loss: 0.1891 - accuracy: 0.9397 - val_loss: 0.5157 - val_accuracy: 0.8917\n",
      "Epoch 47/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.1902 - accuracy: 0.9393 - val_loss: 0.5253 - val_accuracy: 0.8903\n",
      "Epoch 48/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.1822 - accuracy: 0.9416 - val_loss: 0.5321 - val_accuracy: 0.8931\n",
      "Epoch 49/50\n",
      "203/203 [==============================] - 2s 10ms/step - loss: 0.1725 - accuracy: 0.9441 - val_loss: 0.5222 - val_accuracy: 0.8944\n",
      "Epoch 50/50\n",
      "203/203 [==============================] - 2s 8ms/step - loss: 0.1854 - accuracy: 0.9414 - val_loss: 0.4824 - val_accuracy: 0.9014\n",
      "Accuracy: 0.89\n",
      "57/57 [==============================] - 1s 2ms/step\n",
      "Classification Report (RNN):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91       167\n",
      "           1       0.94      0.96      0.95       162\n",
      "           2       0.90      0.83      0.86       203\n",
      "           3       0.85      0.87      0.86       176\n",
      "           4       0.92      0.86      0.89       184\n",
      "           5       0.86      0.94      0.90       177\n",
      "           6       0.95      0.94      0.94       174\n",
      "           7       0.89      0.89      0.89       180\n",
      "           8       0.89      0.88      0.88       188\n",
      "           9       0.81      0.84      0.83       188\n",
      "\n",
      "    accuracy                           0.89      1799\n",
      "   macro avg       0.89      0.89      0.89      1799\n",
      "weighted avg       0.89      0.89      0.89      1799\n",
      "\n",
      "Accuracy (RNN): 0.89\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Load the dataset from a CSV file\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Drop non-numeric columns (e.g., filename) before splitting\n",
    "data = data.drop(\"filename\", axis=1)\n",
    "data = data.drop(\"length\", axis=1)\n",
    "\n",
    "# Define a dictionary to map genre labels to numerical values\n",
    "genre_mapping = {\n",
    "    'blues': 0,\n",
    "    'classical': 1,\n",
    "    'country': 2,\n",
    "    'disco': 3,\n",
    "    'hiphop': 4,\n",
    "    'jazz': 5,\n",
    "    'metal': 6,\n",
    "    'pop': 7,\n",
    "    'reggae': 8,\n",
    "    'rock': 9\n",
    "}\n",
    "\n",
    "# Map genre labels to numerical values using the genre_mapping dictionary\n",
    "data['label'] = data['label'].map(genre_mapping)\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data.drop(\"label\", axis=1)  # Assuming \"label\" is the name of the target column\n",
    "y = data[\"label\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Reshape the input data for LSTM\n",
    "X_train_lstm = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test_lstm = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "# Create an RNN model with LSTM layers\n",
    "rnn_model = Sequential()\n",
    "\n",
    "# First LSTM layer with input shape\n",
    "rnn_model.add(LSTM(128, activation='relu', return_sequences=True, input_shape=(1, X_train.shape[1])))\n",
    "rnn_model.add(Dropout(0.2))  # Dropout layer to prevent overfitting\n",
    "\n",
    "# Second LSTM layer\n",
    "rnn_model.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "rnn_model.add(Dropout(0.2))  # Dropout layer to prevent overfitting\n",
    "\n",
    "# Third LSTM layer\n",
    "rnn_model.add(LSTM(32, activation='relu'))\n",
    "rnn_model.add(Dropout(0.2))  # Dropout layer to prevent overfitting\n",
    "\n",
    "# Dense layers\n",
    "rnn_model.add(Dense(64, activation='relu'))\n",
    "rnn_model.add(Dropout(0.2))  # Dropout layer to prevent overfitting\n",
    "\n",
    "rnn_model.add(Dense(len(genre_mapping), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "rnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the RNN model\n",
    "rnn_model.fit(X_train_lstm, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the RNN model\n",
    "accuracy = rnn_model.evaluate(X_test_lstm, y_test, verbose=0)[1]\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Make predictions on the test data using RNN\n",
    "y_pred_probs_rnn = rnn_model.predict(X_test_lstm)\n",
    "y_pred_rnn = y_pred_probs_rnn.argmax(axis=1)\n",
    "\n",
    "# Get a detailed classification report for RNN predictions\n",
    "classification_rep_rnn = classification_report(y_test, y_pred_rnn)\n",
    "print(\"Classification Report (RNN):\\n\", classification_rep_rnn)\n",
    "\n",
    "# Calculate accuracy for RNN predictions\n",
    "accuracy_rnn = accuracy_score(y_test, y_pred_rnn)\n",
    "print(f\"Accuracy (RNN): {accuracy_rnn:.2f}\")\n",
    "\n",
    "# Save the RNN model\n",
    "rnn_model.save('rnn_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step\n",
      "RNN Predictions have been made and saved to 'predictions_rnn.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Define a dictionary to map genre labels to numerical values\n",
    "genre_mapping = {\n",
    "    'blues': 0,\n",
    "    'classical': 1,\n",
    "    'country': 2,\n",
    "    'disco': 3,\n",
    "    'hiphop': 4,\n",
    "    'jazz': 5,\n",
    "    'metal': 6,\n",
    "    'pop': 7,\n",
    "    'reggae': 8,\n",
    "    'rock': 9\n",
    "}\n",
    "\n",
    "# Reverse the dictionary to perform inverse mapping\n",
    "reverse_genre_mapping = {v: k for k, v in genre_mapping.items()}\n",
    "\n",
    "# Load the test dataset from a CSV file\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "test_data_original_id = test_data['id']\n",
    "\n",
    "# Drop non-numeric columns (e.g., id) before making predictions\n",
    "test_data = test_data.drop(\"id\", axis=1)\n",
    "test_data = test_data.drop(\"length\", axis=1)\n",
    "\n",
    "# Scale the features using the same scaler used for training data\n",
    "scaler = StandardScaler()\n",
    "X_test_data_scaled = scaler.fit_transform(test_data)  # Assuming 'test_data' contains only features\n",
    "\n",
    "# Reshape the input data for LSTM\n",
    "X_test_data_scaled_lstm = X_test_data_scaled.reshape(X_test_data_scaled.shape[0], 1, X_test_data_scaled.shape[1])\n",
    "\n",
    "# Create an RNN model with LSTM layers\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(LSTM(128, activation='relu', input_shape=(1, X_test_data_scaled.shape[1])))\n",
    "rnn_model.add(Dense(10, activation='softmax'))  # Output layer with 10 units for 10 genres\n",
    "\n",
    "# Compile the RNN model\n",
    "rnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Load the trained RNN model\n",
    "rnn_model = load_model('rnn_model.h5')\n",
    "\n",
    "# Make predictions using the trained RNN model\n",
    "y_pred_probabilities_rnn = rnn_model.predict(X_test_data_scaled_lstm)\n",
    "\n",
    "# Get the predicted class labels for RNN\n",
    "y_pred_test_rnn = np.argmax(y_pred_probabilities_rnn, axis=1)\n",
    "\n",
    "# Create a new DataFrame with the original 'id' and predicted labels\n",
    "predictions_df_rnn = pd.DataFrame({\"id\": test_data_original_id, \"label\": y_pred_test_rnn})\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df_rnn.to_csv(\"predictions_rnn1.csv\", index=False)\n",
    "\n",
    "# Print a message indicating successful prediction and saving of the results for RNN\n",
    "print(\"RNN Predictions have been made and saved to 'predictions_rnn.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
